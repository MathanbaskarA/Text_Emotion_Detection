{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqQrfkXmq8yy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TtZlJAE5SxH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file):\n",
        "    data = []  #An empty list data is created to store the results (label and text pairs).\n",
        "    with open(file, 'r')as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
        "            text = line[line.find(\"]\")+1:].strip()\n",
        "            data.append([label, text])\n",
        "    return data\n",
        "\n",
        "file = '/content/text.txt'\n",
        "data = read_data(file)\n",
        "print(\"Number of instances: {}\".format(len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ZNAejshUtb",
        "outputId": "e0a9b638-26dd-47e8-8843-61d404d8290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances: 7480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ngram(token, n):\n",
        "    output = []\n",
        "    for i in range(n-1, len(token)):\n",
        "        ngram = ' '.join(token[i-n+1:i+1])\n",
        "        output.append(ngram)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "qyMQn2Mr0ntA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature(text, nrange=(1, 1)):\n",
        "    text_features = []\n",
        "    text = text.lower()\n",
        "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
        "    for n in range(nrange[0], nrange[1]+1):\n",
        "        text_features += ngram(text_alphanum.split(), n)\n",
        "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
        "    text_features += ngram(text_punc.split(), 1)\n",
        "    return Counter(text_features)"
      ],
      "metadata": {
        "id": "Wiu5infk0rL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label(item, name):\n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)):\n",
        "        if items[idx] == 1:\n",
        "            label += name[idx] + \" \"\n",
        "\n",
        "    return label.strip()\n",
        "\n",
        "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "for label, text in data:\n",
        "    y_all.append(convert_label(label, emotions))\n",
        "    X_all.append(create_feature(text, nrange=(1, 4)))"
      ],
      "metadata": {
        "id": "uPGPIQ-hsEPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n",
        "\n",
        "def train_test(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
        "    return train_acc, test_acc\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vectorizer = DictVectorizer(sparse = True)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "gRiDkSN5slgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC()\n",
        "lsvc = LinearSVC(random_state=123)\n",
        "rforest = RandomForestClassifier(random_state=123)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "clifs = [svc, lsvc, rforest, dtree]\n",
        "\n",
        "# train and test them\n",
        "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
        "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
        "for clf in clifs:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
        "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGNlrGgUspy0",
        "outputId": "a2a24a72-03e1-4e3c-e44f-d15e10297b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Classifier                | Training Accuracy | Test Accuracy |\n",
            "| ------------------------- | ----------------- | ------------- |\n",
            "| SVC                       |         0.9067513 |     0.4512032 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
            "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
            "| DecisionTreeClassifier    |         0.9988302 |     0.4518717 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
        "l.sort()\n",
        "label_freq = {}\n",
        "for label, _ in data:\n",
        "    label_freq[label] = label_freq.get(label, 0) + 1\n",
        "\n",
        "# print the labels and their counts in sorted order\n",
        "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
        "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pke4PtsptyUD",
        "outputId": "f11a0db2-f09b-4ba1-daf4-d0d3ff6231e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
            "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
            "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
            "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
            "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
            "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
            "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dict = {\"joy\":\"ðŸ˜‚\", \"fear\":\"ðŸ˜±\", \"anger\":\"ðŸ˜ \", \"sadness\":\"ðŸ˜¢\", \"disgust\":\"ðŸ˜’\", \"shame\":\"ðŸ˜³\", \"guilt\":\"ðŸ˜³\"}\n",
        "t1 = \"This looks so impressive\"\n",
        "t2 = \"I have a fear of dogs\"\n",
        "t3 = \"My dog died yesterday\"\n",
        "t4 = \"I don't love you anymore..!\"\n",
        "\n",
        "texts = [t1, t2, t3, t4]\n",
        "for text in texts:\n",
        "    features = create_feature(text, nrange=(1, 4))\n",
        "    features = vectorizer.transform(features)\n",
        "    prediction = clf.predict(features)[0]\n",
        "    print( text,emoji_dict[prediction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkAGfgQPt1GM",
        "outputId": "2002159c-8f03-48a4-c66d-d08516141f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This looks so impressive ðŸ˜³\n",
            "I have a fear of dogs ðŸ˜±\n",
            "My dog died yesterday ðŸ˜¢\n",
            "I don't love you anymore..! ðŸ˜‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Intext = input('Enter Text : ')\n",
        "texts = [Intext]\n",
        "for text in texts:\n",
        "    features = create_feature(text, nrange=(0, 1))\n",
        "    features = vectorizer.transform(features)\n",
        "    prediction = clf.predict(features)[0]\n",
        "    print( text,emoji_dict[prediction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeD5ylj5t5Pc",
        "outputId": "ae321c64-cb5a-4a30-e73c-e8490841e500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Text : I feel sad for the issue\n",
            "I feel sad for the issue ðŸ˜¢\n"
          ]
        }
      ]
    }
  ]
}